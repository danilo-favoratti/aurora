# üß¨ RPG Storyteller ‚Äì Tech Component Integration

## üîÅ Overview: How Everything Connects

```mermaid
graph LR
A[Client UI] -- Button click --> B[WebSocket Server (FastAPI)]
B --> C[ChatCompletion API (OpenAI)]
C --> B
B --> D[Image Generation API (DALL¬∑E)]
D --> B
B --> A
```

---

## 1Ô∏è‚É£ Client UI (HTML/JS or React)

### Role:
- Displays streamed narration
- Renders pixel-art scene image
- Shows 2‚Äì4 choice buttons for each turn

### Responsibilities:
```text
- Opens persistent WebSocket connection to backend.
- Waits for streaming narration tokens ‚Üí appends to screen.
- Displays image once received (base64).
- Renders buttons when choices arrive.
- Sends selected choice as JSON: {"choice": "Climb the tower"}
```

---

## 2Ô∏è‚É£ WebSocket Server (FastAPI + Python)

### Role:
Central orchestrator of all backend logic.

### Responsibilities:
```text
- Accepts WebSocket connections per player session.
- On message (user choice):
    1. Builds message history and system prompt.
    2. Calls ChatCompletion API with stream=True.
    3. Forwards each token to the client in real-time.
    4. Buffers and parses complete AI response as JSON.
    5. Triggers image generation from the image_prompt (async).
    6. Sends final choices and image to client when ready.
```

---

## 3Ô∏è‚É£ OpenAI ChatCompletion API

### Role:
Narrates the RPG story based on player choices.

### How it works:
```python
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[...],
    stream=True
)
```

### What it returns:
- Streamed tokens of a JSON-formatted string like:

```json
{
  "narration": "...",
  "choices": ["..."],
  "image_prompt": "..."
}
```

### Backend parses and:
- Streams `narration` tokens as-is
- Extracts `choices` to send at the end
- Launches image generation using `image_prompt`

---

## 4Ô∏è‚É£ Image Generation (DALL¬∑E via OpenAI Image API)

### Role:
Creates pixel-art images that match the described scene.

### Call:
```python
openai.Image.create(
  prompt=image_prompt,
  size="256x256",
  response_format="b64_json"
)
```

### How it interacts:
```text
- Triggered after receiving first sentence or full narration.
- Runs in parallel with text streaming.
- Sends base64-encoded image to client via WebSocket.
```

---

## üîÑ Communication Loop (Per Turn)

```text
1. Client sends selected choice over WebSocket.
2. Server builds prompt with new user message.
3. Server streams ChatCompletion response:
   - Parses and streams `narration` tokens to client.
   - Extracts `image_prompt` and sends to Image API.
4. Once image is ready ‚Üí sends it as base64.
5. Sends new list of `choices` as buttons.
6. Waits for next user choice.
```

---

## üß© How It All Syncs Together

| Component      | Input                             | Output                               | Timing         |
|----------------|-----------------------------------|--------------------------------------|----------------|
| Client UI      | User click                        | Token-by-token text, image, buttons  | Real-time      |
| WebSocket API  | WebSocket message (JSON)          | Text + image + buttons stream        | Always open    |
| Chat API       | Message history + new choice      | Streamed JSON with story, choices    | ~0.5‚Äì2s tokens |
| Image API      | Prompt (from text or field)       | base64 image                         | ~3‚Äì6s async    |

---

